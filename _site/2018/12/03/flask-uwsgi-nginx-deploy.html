<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      
      Deploy Keras Model with Flask+uWSGI+NGINX with Docker
      
    </title>
    <link rel="shortcut icon" type="image/x-icon" href="/assets/res/favicon.ico">
	<!--
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/css/materialize.min.css">
	-->
    <link rel="stylesheet" href="/assets/css/materialize.min.css">
    <link rel="stylesheet" href="/assets/css/Material+Icons.css">
    <link rel="stylesheet" href="/assets/css/main.css">
    
    
    <link rel="stylesheet" href="/assets/css/post.css">
    
    
    
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml">
    <!-- Begin Jekyll SEO tag v2.5.0 -->
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Deploy Keras Model with Flask+uWSGI+NGINX with Docker" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="After spending more than 200 credits on google cloud GPU for training a Plant Disease Recoginition (PDR) model with Keras, I’ve got a decent model that have reached more than 85% accuracy. The model is ready and the next thing to do is to deploy the model for inference as a service." />
<meta property="og:description" content="After spending more than 200 credits on google cloud GPU for training a Plant Disease Recoginition (PDR) model with Keras, I’ve got a decent model that have reached more than 85% accuracy. The model is ready and the next thing to do is to deploy the model for inference as a service." />
<link rel="canonical" href="http://localhost:4000/2018/12/03/flask-uwsgi-nginx-deploy" />
<meta property="og:url" content="http://localhost:4000/2018/12/03/flask-uwsgi-nginx-deploy" />
<meta property="og:site_name" content="ZKF’s Playground" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-12-03T15:21:00+08:00" />
<script type="application/ld+json">
{"description":"After spending more than 200 credits on google cloud GPU for training a Plant Disease Recoginition (PDR) model with Keras, I’ve got a decent model that have reached more than 85% accuracy. The model is ready and the next thing to do is to deploy the model for inference as a service.","@type":"BlogPosting","url":"http://localhost:4000/2018/12/03/flask-uwsgi-nginx-deploy","headline":"Deploy Keras Model with Flask+uWSGI+NGINX with Docker","dateModified":"2018-12-03T15:21:00+08:00","datePublished":"2018-12-03T15:21:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2018/12/03/flask-uwsgi-nginx-deploy"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <header>
	  <!--
      <nav class="top-nav teal">
	  -->
      <nav class="top-nav ohio-state-scarlet">
        <div class="nav-wrapper">
          <div class="container">
            <a class="page-title" href="/">ZKF's Playground</a>
            <img class="buckeye_leaf" src="/assets/res/buckeye_leaf.png">
          </div>
        </div>
      </nav>
      <div class="container">
        <a href="#" data-activates="slide-out" class="button-collapse top-nav full hide-on-large-only">
          <i class="material-icons">menu</i>
        </a>
      </div>
      <ul id="slide-out" class="side-nav fixed">
        <li>
          <div class="userView">
            <div class="background"></div>
            <a href="https://github.com/zkf85" target="_blank"><img class="circle z-depth-2" src="/assets/res/lion_king.jpg"></a>
            <span class="white-text name">Zhu, Kefeng</span>
			<!--
            <span class="white-text email">zkf1985@gmail.com</span>
			-->
            <span class="white-text email"><i>A Programmer, An AI Practitioner</i></span>
          </div>
        </li>
        <li><a class="waves-effect" href="/"><i class="material-icons">home</i>Home</a></li>
<!--
<li><a class="waves-effect" href="/projects"><i class="material-icons">description</i>Projects</a></li>
-->
        <li><a class="waves-effect" href="/categories"><i class="material-icons">sort</i>Categories</a></li>
        <li><a class="waves-effect" href="/tags"><i class="material-icons">label</i>Tags</a></li>
<!--
<li><a class="waves-effect" href="/feed.xml" target="_blank"><i class="material-icons">rss_feed</i>RSS</a></li>
-->
        <li><div class="divider"></div></li>
        <li><a class="waves-effect" href="/about"><i class="material-icons">person</i>About Me</a></li>
        <li><a class="waves-effect" href="/contact"><i class="material-icons">email</i>Contact</a></li>
      </ul>
    </header>
    <main>

<!--
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
-->
<!-- KF 02/14/2019
The following snippet is to allow single $ style inline mode.
Remember that after enabling this, you have to enter the real dollar sings with `\$`
-->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<div class="container">
  <div id="post-info">
  <h1>Deploy Keras Model with Flask+uWSGI+NGINX with Docker</h1>
  <ul class="collapsible hoverable" data-collapsible="accordion">
    <li>
      <div class="collapsible-header">
        <span>
          <i class="material-icons tooltipped" data-position="left" data-delay="30" data-tooltip="Date">date_range</i>
          12/03/2018 15:21
          <i id="indicate" class="right material-icons tooltipped" data-position="left" data-delay="30" data-tooltip="Show extra info">info</i>
        </span>
      </div>
      <div class="collapsible-body">
        <span>
          <i class="material-icons tooltipped" data-position="left" data-delay="30" data-tooltip="Categories">sort</i>
          
          
          
          <a href="/categories#operating-system_cap" target="_blank"><div class="chip">Operating System</div></a>
          
          
          
          <a href="/categories#deep-learning_cap" target="_blank"><div class="chip">Deep Learning</div></a>
          
        </span>
        <span>
          <i class="material-icons tooltipped" data-position="left" data-delay="30" data-tooltip="Tags">label</i>
          
          
          
          <a href="/tags#docker" target="_blank"><div class="chip">docker</div></a>
          
          
          
          <a href="/tags#flask" target="_blank"><div class="chip">flask</div></a>
          
          
          
          <a href="/tags#uwsgi" target="_blank"><div class="chip">uwsgi</div></a>
          
          
          
          <a href="/tags#nginx" target="_blank"><div class="chip">nginx</div></a>
          
          
          
          <a href="/tags#keras" target="_blank"><div class="chip">keras</div></a>
          
          
          
          <a href="/tags#tensorflow" target="_blank"><div class="chip">tensorflow</div></a>
          
        </span>
      </div>
    </li>
  </ul>
</div>
<div class="divider"></div>
<div class="row">
  <div class="col s12">
    <blockquote>
  <p>After spending more than 200 credits on google cloud GPU for training a <strong>Plant Disease Recoginition (PDR)</strong> model with Keras, I’ve got a decent model that have reached more than 85% accuracy. The model is ready and the next thing to do is to deploy the model for inference as a service.</p>
</blockquote>

<p><!--more--></p>

<ul id="markdown-toc">
  <li><a href="#1-background" id="markdown-toc-1-background">1. Background</a>    <ul>
      <li><a href="#11-objective" id="markdown-toc-11-objective">1.1. Objective</a></li>
      <li><a href="#12-what-we-have" id="markdown-toc-12-what-we-have">1.2. What we have?</a></li>
      <li><a href="#13-what-strategy-we-choose" id="markdown-toc-13-what-strategy-we-choose">1.3. What strategy we choose?</a></li>
    </ul>
  </li>
  <li><a href="#2-deploy-the-flask--uwsgi--nginx-fun-combo-manually" id="markdown-toc-2-deploy-the-flask--uwsgi--nginx-fun-combo-manually">2. Deploy the <strong>Flask + uWSGI + NGINX</strong> (FUN) Combo Manually</a>    <ul>
      <li><a href="#21-flask" id="markdown-toc-21-flask">2.1. Flask</a></li>
      <li><a href="#22-test-the-api" id="markdown-toc-22-test-the-api">2.2. Test the API</a></li>
      <li><a href="#23-uwsgi" id="markdown-toc-23-uwsgi">2.3. uWSGI</a>        <ul>
          <li><a href="#231-create-a-uwsgi-configuration-file" id="markdown-toc-231-create-a-uwsgi-configuration-file">2.3.1. Create a uWSGI Configuration File</a></li>
          <li><a href="#232-creating-a-systemd-unit-file" id="markdown-toc-232-creating-a-systemd-unit-file">2.3.2. Creating a systemd Unit File</a></li>
        </ul>
      </li>
      <li><a href="#24-configuring-nginx-to-proxy-requests" id="markdown-toc-24-configuring-nginx-to-proxy-requests">2.4. Configuring Nginx to Proxy Requests</a></li>
      <li><a href="#25-test-the-newly-established-api" id="markdown-toc-25-test-the-newly-established-api">2.5 Test the newly established API</a></li>
    </ul>
  </li>
  <li><a href="#3-deploy-flask--uwsgi--nginx-fun-combo-with-docker" id="markdown-toc-3-deploy-flask--uwsgi--nginx-fun-combo-with-docker">3. Deploy <strong>Flask + uWSGI + NGINX</strong> (FUN) combo with Docker</a>    <ul>
      <li><a href="#31-build-a-customized-version-of-docker-image" id="markdown-toc-31-build-a-customized-version-of-docker-image">3.1. Build a customized version of docker image</a></li>
      <li><a href="#32-create-and-run-a-docker-container-with-the-customized-image" id="markdown-toc-32-create-and-run-a-docker-container-with-the-customized-image">3.2. Create and run a Docker container with the customized image</a></li>
      <li><a href="#33-wrap-it-up-and-deploy-it-anywhere-else" id="markdown-toc-33-wrap-it-up-and-deploy-it-anywhere-else">3.3. Wrap it up and deploy it anywhere else</a></li>
    </ul>
  </li>
  <li><a href="#4-conclusion" id="markdown-toc-4-conclusion">4. Conclusion</a></li>
</ul>

<h2 id="1-background">1. Background</h2>

<h3 id="11-objective">1.1. Objective</h3>
<p>The main objective is to build a web service API which responds with a inference result as a json file after receiving a request with an image in it.</p>

<h3 id="12-what-we-have">1.2. What we have?</h3>
<p>At the moment, we have a well-built keras model, trained with <code class="highlighter-rouge">keras==2.2.4</code> and <code class="highlighter-rouge">tensorflow==1.11.0</code> in <code class="highlighter-rouge">python==3.5.2</code>.</p>

<h3 id="13-what-strategy-we-choose">1.3. What strategy we choose?</h3>
<p>Basically, it’s <strong>“Flask + uWSGI + NGINX”</strong>:</p>

<ul>
  <li><a href="http://flask.pocoo.org">Flask</a> is a good python microframework for web development. It is pretty easy to make an improvised API with Flask. But it’s not recommended to use it to build a formal production.</li>
  <li><a href="https://uwsgi-docs-additions.readthedocs.io/en/latest/">uWSGI</a> aims at developing a full stack for building hosting services. uWSGI is implemented as a linker between Nginx(does not support python) and Flask(written in python).</li>
  <li><a href="https://www.nginx.com/resources/wiki/">NGINX</a>  ( <a href="https://en.wikipedia.org/wiki/Nginx">/ˌɛndʒɪnˈɛks/ EN-jin-EKS</a>) is a free, open-source, high-performance HTTP server and reverse proxy.</li>
</ul>

<h2 id="2-deploy-the-flask--uwsgi--nginx-fun-combo-manually">2. Deploy the <strong>Flask + uWSGI + NGINX</strong> (FUN) Combo Manually</h2>

<p>Before everything, there’s a complete tutorial on <code class="highlighter-rouge">digitalocean</code> about this:</p>

<p><a href="https://www.digitalocean.com/community/tutorials/how-to-serve-flask-applications-with-uswgi-and-nginx-on-ubuntu-18-04">» <strong>How to serve Flask Application with uWSGI and NGINX on Ubuntu 18.04</strong></a></p>

<h3 id="21-flask">2.1. Flask</h3>
<p>Here are the basic steps for setting up Flask:</p>

<p>In your main python script (e.g. <code class="highlighter-rouge">myproject.py</code>),
Import related tools:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">flask</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">Response</span>
</code></pre></div></div>

<p>Initialize the Flask application:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>
</code></pre></div></div>

<p>Setup the app route and method, return the response as JSON file:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@app.route</span><span class="p">(</span><span class="s">'/predict'</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">'POST'</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">():</span>
<span class="o">...</span>
<span class="n">response</span> <span class="o">=</span> <span class="o">...</span>

<span class="k">return</span> <span class="n">flask</span><span class="o">.</span><span class="n">jsonify</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>

</code></pre></div></div>

<p>A complete sample code of <code class="highlighter-rouge">myproject.py</code> is listed below:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Filename   :  myproject.py</span>
<span class="c"># Written by :  KF </span>

<span class="kn">import</span> <span class="nn">flask</span>
<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">Response</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">load_img</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">img_to_array</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c"># Initialize the Flask application</span>
<span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">init</span><span class="p">():</span>

<span class="k">global</span> <span class="n">model</span><span class="p">,</span> <span class="n">img_shape</span><span class="p">,</span> <span class="n">idx_dict</span>
<span class="k">global</span> <span class="n">graph</span>

<span class="c"># Basic parameters</span>
<span class="n">model_file_name</span> <span class="o">=</span> <span class="s">"disease_224.model"</span>
<span class="n">label_file_name</span> <span class="o">=</span> <span class="s">"labels.npz"</span>
<span class="n">img_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c"># Load Keras model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_file_name</span><span class="p">)</span>
<span class="c"># Initialize a global graph for Keras/tensorflow</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
<span class="c"># Load index-label list (not important here in this article)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">label_file_name</span><span class="p">)</span>
<span class="n">label_dict</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="s">'class_idx'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">idx_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">y</span><span class="p">:</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">label_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c"># route http posts to this method</span>
<span class="nd">@app.route</span><span class="p">(</span><span class="s">'/predict'</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">'POST'</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">():</span>

<span class="c"># Get the image in the POST request </span>
<span class="n">image_file</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">files</span><span class="p">[</span><span class="s">'image'</span><span class="p">]</span>

<span class="c"># Load the image for Keras model</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">load_img</span><span class="p">(</span><span class="n">image_file</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="n">img_shape</span><span class="p">)</span>

<span class="n">img_np</span> <span class="o">=</span> <span class="n">img_to_array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">/</span><span class="mf">255.0</span>
<span class="n">img_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c"># Predict</span>
<span class="k">with</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
	<span class="k">print</span><span class="p">(</span><span class="s">'Start predicting ...'</span><span class="p">)</span>
	<span class="n">proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img_np</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
	<span class="c">#proba = [1,2,3,4,5]</span>
	<span class="k">print</span><span class="p">(</span><span class="s">'Prediction complete！'</span><span class="p">)</span>

<span class="n">res_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">proba</span><span class="p">)</span>

<span class="c"># Mapping the result index to label (not important for this article)</span>
<span class="n">best_prediction_label</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">idx_dict</span><span class="p">[</span><span class="n">res_idx</span><span class="p">])</span>

<span class="c"># Build a response dict to send back to client</span>
<span class="n">response</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">response</span><span class="p">[</span><span class="s">'message'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'image received!'</span>
<span class="n">response</span><span class="p">[</span><span class="s">'best_prediction'</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_prediction_label</span>

<span class="k">return</span> <span class="n">flask</span><span class="o">.</span><span class="n">jsonify</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>


<span class="c"># Initialize first no matter if it's main or not ...</span>
<span class="n">init</span><span class="p">()</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
<span class="k">print</span><span class="p">((</span><span class="s">"* Loading Keras model and Flask starting server..."</span>
<span class="s">"please wait until server has fully started"</span><span class="p">))</span>
<span class="c"># start the flask app, allow remote connection</span>
<span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="s">'0.0.0.0'</span><span class="p">,</span> <span class="n">threaded</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p><strong>Note</strong>:</p>
  <ol>
    <li>Anytime this main <code class="highlighter-rouge">myproject.py</code> script is called, the model loading and parameters loading steps should be put in the <code class="highlighter-rouge">init()</code> in order to avoid running the slow process everytime when predicting.</li>
    <li>In the initialization, a global <code class="highlighter-rouge">graph</code> for keras/tensorflow is initialized. Without this, there’ll be an error.</li>
    <li>To change the port (e.g. change to 8000, simply change the last line to <code class="highlighter-rouge">app.run(host='0.0.0.0', port='8000')</code>.</li>
  </ol>
</blockquote>

<p>Run/Test the API with Flask simply by:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python myproject.py
</code></pre></div></div>

<p>If the log is as below, it means the Flask API is working well,</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">*</span> Loading Keras model and Flask starting server...please <span class="nb">wait </span><span class="k">until </span>server has fully started
<span class="k">*</span> Serving Flask app <span class="s2">"myproject"</span> <span class="o">(</span>lazy loading<span class="o">)</span>
<span class="k">*</span> Environment: production
   WARNING: Do not use the development server <span class="k">in </span>a production environment.
   Use a production WSGI server instead.
<span class="k">*</span> Debug mode: off
<span class="k">*</span> Running on http://0.0.0.0:5000/ <span class="o">(</span>Press CTRL+C to quit<span class="o">)</span>

</code></pre></div></div>

<h3 id="22-test-the-api">2.2. Test the API</h3>

<p>On another computer, write a <code class="highlighter-rouge">POST</code> request in python using <code class="highlighter-rouge">requests</code> library.
In <code class="highlighter-rouge">api_test.py</code>:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Filename   :  api_test.py</span>
<span class="c"># Written by :  KF </span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">addr</span> <span class="o">=</span> <span class="s">'http://192.168.1.235:5000'</span>
<span class="c">#addr = 'http://192.168.1.235'</span>
<span class="n">test_url</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">addr</span><span class="p">,</span> <span class="s">'predict'</span><span class="p">)</span>

<span class="n">files</span> <span class="o">=</span> <span class="p">{</span><span class="s">'image'</span><span class="p">:</span> <span class="nb">open</span><span class="p">(</span><span class="s">'test_image.JPG'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)}</span>

<span class="c"># send http request with image and receive response</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">test_url</span><span class="p">,</span> <span class="n">files</span><span class="o">=</span><span class="n">files</span><span class="p">)</span>

<span class="c">#decode response</span>
<span class="k">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</code></pre></div></div>

<p>If you followed the initial server setup guide, you should have a UFW firewall enabled. To test the application, you need to allow access to port 5000:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>ufw allow 5000
</code></pre></div></div>

<p>Make sure that the ip address and port number is correct. Then it should work.</p>

<h3 id="23-uwsgi">2.3. uWSGI</h3>
<p>As we can see in the log info of running Flask, it warns that <strong><code class="highlighter-rouge">"Do not use the development server in a production environment"</code></strong>, which means that Flask by itself is “OK” for testing in development but <strong>not</strong> designed for production. Therefore, we need to deploy it in a more professional environment, as it says, <strong>“Use a production WSGI server instead”</strong>.</p>

<p><a href="https://uwsgi-docs-additions.readthedocs.io/en/latest/">uWSGI (WSGI - Web Server Gateway Interface)</a> is used here as a tool for connecting <strong>Flask</strong> and <strong>NGINX</strong>.</p>

<h4 id="231-create-a-uwsgi-configuration-file">2.3.1. Create a uWSGI Configuration File</h4>
<p>Let’s place that file in our project directory and call it <code class="highlighter-rouge">myproject.ini</code>, in the file, add the following snippet:</p>
<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[uwsgi]</span>
<span class="py">module</span> <span class="p">=</span> <span class="s">wsgi:app</span>

<span class="py">processes</span> <span class="p">=</span> <span class="s">1</span>
<span class="py">vacuum</span> <span class="p">=</span> <span class="s">true</span>
<span class="py">die-on-term</span> <span class="p">=</span> <span class="s">true</span>
<span class="py">socket</span> <span class="p">=</span> <span class="s">/tmp/myproject.sock</span>
<span class="py">chmod-socket</span> <span class="p">=</span> <span class="s">666</span>

<span class="c">#master = true
</span><span class="py">master</span> <span class="p">=</span> <span class="s">false</span>
</code></pre></div></div>
<blockquote>
  <p><strong>Note</strong>:</p>
  <ol>
    <li><code class="highlighter-rouge">socket</code> points to a temporery file generated later when the service is on, pointing it to <code class="highlighter-rouge">/tmp/</code> and change its permission to 666 make sure there’s not a permission problem.</li>
    <li><code class="highlighter-rouge">processes</code> is set to <code class="highlighter-rouge">1</code> in my case. If not, my API will be stuck at the prediction step.</li>
    <li><code class="highlighter-rouge">master</code> is set to <code class="highlighter-rouge">false</code>. If not, my API will be stuck at t he prediction step.</li>
  </ol>
</blockquote>

<h4 id="232-creating-a-systemd-unit-file">2.3.2. Creating a systemd Unit File</h4>
<p>Next, let’s create the systemd service unit file. Creating a systemd unit file will allow Ubuntu’s init system to automatically start uWSGI and serve the Flask application whenever the server boots.</p>

<p>Create a unit file ends with .service (e.g. <code class="highlighter-rouge">myproject.service</code>) within the <code class="highlighter-rouge">/etc/systemd/system</code> directory with the following snippet:</p>
<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>                                                                                                                
<span class="py">Description</span><span class="p">=</span><span class="s">uWSGI instance to serve myproject</span>
<span class="py">After</span><span class="p">=</span><span class="s">network.target</span>

<span class="nn">[Service]</span>
<span class="py">User</span><span class="p">=</span><span class="s">kefeng</span>
<span class="py">Group</span><span class="p">=</span><span class="s">www-data</span>

<span class="py">WorkingDirectory</span><span class="p">=</span><span class="s">/home/kefeng/PlantDiseaseRecognition/myproject</span>
<span class="py">Environment</span><span class="p">=</span><span class="s">"PATH=/home/kefeng/anaconda3/bin"</span>

<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/uwsgi --ini myproject.ini</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<p>We can now start the uWSGI service we created and enable it so that it starts at boot:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl start myproject
<span class="nv">$ </span><span class="nb">sudo </span>systemctl <span class="nb">enable </span>myproject
</code></pre></div></div>

<p>Check the status:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl status myproject
</code></pre></div></div>

<p>The output should be like this:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>● myproject.service - uWSGI instance to serve myproject
   Loaded: loaded (/etc/systemd/system/myproject.service; disabled; vendor preset: enabled)
   Active: active (running) since Mon 2018-12-03 17:58:25 CST; 1h 7min ago
 Main PID: 3889 (uwsgi)
    Tasks: 13 (limit: 4915)
   CGroup: /system.slice/myproject.service
           └─3889 /usr/local/bin/uwsgi --ini myproject.ini

</code></pre></div></div>

<h3 id="24-configuring-nginx-to-proxy-requests">2.4. Configuring Nginx to Proxy Requests</h3>
<p>Our uWSGI application server should now be up and running, waiting for requests on the socket file in the project directory. Let’s configure Nginx to pass web requests to that socket using the <code class="highlighter-rouge">uwsgi</code> protocol.</p>

<p>Create a new server block configuration file in Nginx’s sites-available directory (e.g. <code class="highlighter-rouge">myproject</code>):</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>vi /etc/nginx/sites-available/myproject
</code></pre></div></div>

<p>Code in <code class="highlighter-rouge">/etc/nginx/sites-available/myproject</code>:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>server {
    listen 80;
    server_name 192.168.1.235;

    location / {
        try_files $uri @app;
    }
    location @app {
        include uwsgi_params;
        uwsgi_pass unix:///tmp/myproject.sock;
    }
}
</code></pre></div></div>

<p>To enable the Nginx server block configuration you’ve just created, link the file to the sites-enabled directory:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>ln <span class="nt">-s</span> /etc/nginx/sites-available/myproject /etc/nginx/sites-enabled
</code></pre></div></div>

<p>With the file in that directory, we can test for syntax errors by typing:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>nginx <span class="nt">-t</span>
</code></pre></div></div>

<p>If this returns without indicating any issues, restart the Nginx process to read the new configuration:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl restart nginx
</code></pre></div></div>

<p>Adjust the firewall again. We no longer need access through port 5000, so we can remove that rule. We can then allow access to the Nginx server:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>ufw delete allow 5000
<span class="nv">$ </span><span class="nb">sudo </span>ufw allow <span class="s1">'Nginx Full'</span>
</code></pre></div></div>

<p>If you encounter any errors, trying checking the following:</p>
<ul>
  <li><code class="highlighter-rouge">sudo less /var/log/nginx/error.log: checks the Nginx error logs.</code></li>
  <li><code class="highlighter-rouge">sudo less /var/log/nginx/access.log: checks the Nginx access logs.</code></li>
  <li><code class="highlighter-rouge">sudo journalctl -u nginx: checks the Nginx process logs.</code></li>
  <li><code class="highlighter-rouge">sudo journalctl -u myproject: checks your Flask app's uWSGI logs.</code></li>
</ul>

<h3 id="25-test-the-newly-established-api">2.5 Test the newly established API</h3>
<p>Use the same python file created in 2.2, only remove the port number since the nginx api use the default port 80.</p>

<p>In <code class="highlighter-rouge">api_test.py</code>, make the following change:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">addr</span> <span class="o">=</span> <span class="s">'http://192.168.1.235'</span>
</code></pre></div></div>

<p>It should work fine as the same as with Flask alone.</p>

<h2 id="3-deploy-flask--uwsgi--nginx-fun-combo-with-docker">3. Deploy <strong>Flask + uWSGI + NGINX</strong> (FUN) combo with Docker</h2>

<p>Using Docker to deploy the service is much easier. You can save most work described above.</p>

<p>Check out <a href="https://github.com/tiangolo/uwsgi-nginx-flask-docker"><code class="highlighter-rouge">tiangolo/uwsgi-nginx-flask-docker</code></a> to find and download a suitable version of <code class="highlighter-rouge">Dockerfile</code>.</p>

<p>For Docker basics, see my previous article about Docker.</p>

<h3 id="31-build-a-customized-version-of-docker-image">3.1. Build a customized version of docker image</h3>
<p>In my case, I use <code class="highlighter-rouge">python3.6</code> version image. Besides, it is good practice to build a customized version of image for yourself since</p>
<ol>
  <li>Several additional python package need to be installed in the Docker;</li>
  <li>Some minor modifications are needed for the nginx service;</li>
</ol>

<p>First, create a folder with a <code class="highlighter-rouge">Dockerfile</code> in it;</p>

<p>Create a <code class="highlighter-rouge">requirements.txt</code> file for additional python packages to be installed in the Docker image.</p>

<p>In my <code class="highlighter-rouge">requirements.txt</code>:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>keras==2.2.4
tensorflow==1.11.0
pillow
numpy
</code></pre></div></div>

<p>The default nginx body buffer size is too small for a POST request with an image in it. Therefore, you need to modifiy this parameter by copy a <code class="highlighter-rouge">.conf</code> file into the Docker image.</p>

<p>Create a file <code class="highlighter-rouge">kf_upload.conf</code>, in which add:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>client_body_buffer_size 5m;
</code></pre></div></div>

<p>Then, write the <code class="highlighter-rouge">Dockerfile</code> as below:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FROM tiangolo/uwsgi-nginx-flask:python3.6

COPY requirements.txt /
COPY kf_upload.conf /etc/nginx/conf.d/
RUN pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r /requirements.txt
</code></pre></div></div>

<p>Finally, in the directory including <code class="highlighter-rouge">Dockerfile</code> build a customized version of Docker image by:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker build <span class="nt">-t</span> kf-customized-image <span class="nb">.</span>
</code></pre></div></div>
<blockquote>
  <p>Note that the <code class="highlighter-rouge">kf-customized-image</code> is the name of the new image you build. You may change it to anything you like.</p>
</blockquote>

<h3 id="32-create-and-run-a-docker-container-with-the-customized-image">3.2. Create and run a Docker container with the customized image</h3>
<p>Create a new folder for deploying you api, in which there’s a <code class="highlighter-rouge">Dockerfile</code> and a subfolder named <code class="highlighter-rouge">app</code>.</p>

<p>Copy the <code class="highlighter-rouge">myproject.py</code> file mentioned in the previous section into the <code class="highlighter-rouge">app</code> folder, rename it as <code class="highlighter-rouge">main.py</code>. Also remember to copy the files used in the <code class="highlighter-rouge">main.py</code> (e.g. <code class="highlighter-rouge">disease.model</code>, <code class="highlighter-rouge">labels.npz</code>) in to <code class="highlighter-rouge">app</code> folder too.</p>

<p>In the base folder (which inlcudes th <code class="highlighter-rouge">app</code> folder and the <code class="highlighter-rouge">Dockerfile</code>), create a <code class="highlighter-rouge">uwsgi.ini</code> file, add the following code:</p>
<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[uwsgi]</span>
<span class="py">socket</span> <span class="p">=</span> <span class="s">/tmp/uwsgi.sock</span>
<span class="py">chown-socket</span> <span class="p">=</span> <span class="s">nginx:nginx</span>
<span class="py">chmod-socket</span> <span class="p">=</span> <span class="s">664</span>
<span class="py">cheaper</span> <span class="p">=</span> <span class="s">0</span>
<span class="py">processes</span> <span class="p">=</span> <span class="s">1</span>
<span class="py">master</span> <span class="p">=</span> <span class="s">false</span>
</code></pre></div></div>

<p>Then, add the following code into the <code class="highlighter-rouge">Dockerfile</code>:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FROM kf-customized-image
COPY uwsgi.ini /etc/uwsgi/

COPY ./app /app
</code></pre></div></div>

<p>Build the final version of image that is ready to use, in the base folder:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker build <span class="nt">-t</span> kf-ready-to-deploy-image <span class="nb">.</span>
</code></pre></div></div>

<p>Now, everything is ready for deployment. You can check if your image is ready in your Docker by:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker image <span class="nb">ls</span>
</code></pre></div></div>

<p>Finally, one last step you need to do is to run the image as a container.</p>

<p>In any working directory, just run:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker run <span class="nt">-p</span> 80:80 kf-ready-to-deploy-image
</code></pre></div></div>

<blockquote>
  <p>Note that the <code class="highlighter-rouge">-p</code> parameter is to map the Docker internal port (e.g. <code class="highlighter-rouge">80</code>) to your actual machine’s port (e.g. <code class="highlighter-rouge">80</code>).</p>
</blockquote>

<p>Then the  API should be working fine.</p>

<p>You may use the same <code class="highlighter-rouge">api-test.py</code> on another computer (in the same internal network) to test if the API works appropriately. Remember to make sure that the testing port is consistent with the one set in your service.</p>

<h3 id="33-wrap-it-up-and-deploy-it-anywhere-else">3.3. Wrap it up and deploy it anywhere else</h3>
<p>The advantage of using Docker is for its compatibility. As long as Docker is installed on your platform, no matter its Windows, Linux or macOS, you can simply deploy your service by running the image you built.</p>

<p>There are two ways to scale your self-built image:</p>
<ol>
  <li>Log in your Dockerhub account and publish your image, after which, import your image by enter its unique name:
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nv">$ </span>docker login             <span class="c"># Log in this CLI session using your Docker credentials</span>
 <span class="nv">$ </span>docker tag &lt;image&gt; username/repository:tag  <span class="c"># Tag &lt;image&gt; for upload to registry</span>
 <span class="nv">$ </span>docker push username/repository:tag            <span class="c"># Upload tagged image to registry</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Save the Docker image into a <code class="highlighter-rouge">.tar</code> file. Load the <code class="highlighter-rouge">.tar</code> file on any destination machine.</p>

    <p>Save the Docker image with (the two commands belows are the same):</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nv">$ </span>docker save <span class="nt">--output</span> kf-ready-to-deploy-image.tar kf-ready-to-deploy-image
 <span class="nv">$ </span>docker save <span class="nt">-o</span> kf-ready-to-deploy-image.tar kf-ready-to-deploy-image
</code></pre></div>    </div>

    <p>Load the Docker image with (the two commands belows are the same):</p>
    <div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nv">$ </span>docker load <span class="nt">--input</span> kf-ready-to-deploy-image.tar
 <span class="nv">$ </span>docker load <span class="nt">-i</span> kf-ready-to-deploy-image.tar
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="4-conclusion">4. Conclusion</h2>
<p>There’re not a lot of articles on deploying Keras models for production, thus I write this complete instruction on how to deploy Keras model with Flask+uWSGI+NGINX strategy. There are two ways to manage the work: 1) configure everything step by step; 2) apply docker to save your time. Both methods can provide the same production-level API with your well-trained Keras model.</p>

<p><br /><br /><strong><em>KF</em></strong></p>

  </div>
</div>


<div>
<h2>Comments</h2>
<div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    this.page.url = "http://localhost:4000/2018/12/03/flask-uwsgi-nginx-deploy";
    this.page.identifier = "/2018/12/03/flask-uwsgi-nginx-deploy";
  };
  (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = '//zkf85githubio.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>



</div>

<!-- KF 02/13/2019  -->
<!-- Add back to top button -->
<button onclick="topFunction()" id="myBtn" title="Back to top">Top</button>

<script>
// When the user scrolls down 20px from the top of the document, show the button
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
  if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
    document.getElementById("myBtn").style.display = "block";
  } else {
    document.getElementById("myBtn").style.display = "none";
  }
}

// When the user clicks on the button, scroll to the top of the document
function topFunction() {
  document.body.scrollTop = 0;
  document.documentElement.scrollTop = 0;
}
</script>
    </main>
    <footer class="page-footer ohio-state-scarlet">
      <div class="container">
        <div class="row">
          <div class="col s12">
            <img src="/assets/res/logo.png" alt="logo"/>
            <p class="grey-text text-lighten-4">Theme based on <a href="http://materializecss.com">Materialize.css</a> for jekyll sites.
</p>
          </div>
        </div>
      </div>
      <div class="footer-copyright">
        <div class="container">
          &#xA9; 2019 ZKF's Playground. All rights reserved. Powered by <a href="https://github.com/zkf85">Kefeng</a>.
        </div>
      </div>
    </footer>
    <script src="//code.jquery.com/jquery-2.2.4.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/materialize/0.99.0/js/materialize.min.js"></script>
    
    
    <script src="/assets/js/post.js"></script>
    
    
    
    
    <script src="/assets/js/main.js"></script>
  </body>
</html>

