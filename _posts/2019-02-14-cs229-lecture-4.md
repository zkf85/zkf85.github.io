---
layout: post
comments: true
title: "[CS229] Lecture 4 Notes"
date: "2019-02-14 10:40:00"
category: [Notes]
tag: [cs229, machine learning]
---

> CS229 Lecture #4
> 1. Newton's Method,
> 2. Generalized Linear Models


<!--more-->
* TOC
{:toc}

## 1. Newton's Method
### 1.1. Basic idea of Newton's method
The aim of Newton's method is **to find a zero of a function**.

[>> Newton's Method on Wikipedia](https://en.wikipedia.org/wiki/Newton%27s_method)

| ![This is the caption!!!](/public/img/20190214_NewtonIteration_Ani.gif) |
| :-- |
| **Figure 1.** The function \\(f\\) is shown in blue and the tangent line is in red. We see that \\(x_{n + 1}\\) is a better approximation than \\(x_n\\) for the root x of the function \\(f\\). |

### 1.2. Use Newton's method to maximize some function \\(l\\)
The maxima of \\(l\\) correspond to points where it's first derivative \\(l'(\theta)\\) is zero!


| asdf  | asdf  | vcz  |
| --- | --- | --- |
| kfakl; | asfk;l | df  |


$$
\theta := \theta - \frac{f(\theta)}{f'(\theta)}.
$$


## Reference 
1. [>> Stanf Lecture Note Part I & II](https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf)

<br><br>***KF***
